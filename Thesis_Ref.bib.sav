% Encoding: UTF-8

@Article{,
  author      = {Michal Kosinski},
  title       = {Theory of Mind May Have Spontaneously Emerged in Large Language Models},
  abstract    = {Theory of mind (ToM), or the ability to impute unobservable mental states to others, is central to human social interactions, communication, empathy, self-consciousness, and morality. We tested several language models using 40 classic false-belief tasks widely used to test ToM in humans. The models published before 2020 showed virtually no ability to solve ToM tasks. Yet, the first version of GPT-3 ("davinci-001"), published in May 2020, solved about 40% of false-belief tasks-performance comparable with 3.5-year-old children. Its second version ("davinci-002"; January 2022) solved 70% of false-belief tasks, performance comparable with six-year-olds. Its most recent version, GPT-3.5 ("davinci-003"; November 2022), solved 90% of false-belief tasks, at the level of seven-year-olds. GPT-4 published in March 2023 solved nearly all the tasks (95%). These findings suggest that ToM-like ability (thus far considered to be uniquely human) may have spontaneously emerged as a byproduct of language models' improving language skills.},
  date        = {2023-02-04},
  eprint      = {2302.02083v3},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/2302.02083v3:PDF},
  keywords    = {cs.CL, cs.CY, cs.HC},
}

@Article{,
  author      = {SÃ©bastien Bubeck and Varun Chandrasekaran and Ronen Eldan and Johannes Gehrke and Eric Horvitz and Ece Kamar and Peter Lee and Yin Tat Lee and Yuanzhi Li and Scott Lundberg and Harsha Nori and Hamid Palangi and Marco Tulio Ribeiro and Yi Zhang},
  title       = {Sparks of Artificial General Intelligence: Early experiments with GPT-4},
  abstract    = {Artificial intelligence (AI) researchers have been developing and refining large language models (LLMs) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. The latest model developed by OpenAI, GPT-4, was trained using an unprecedented scale of compute and data. In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT-4 is part of a new cohort of LLMs (along with ChatGPT and Google's PaLM for example) that exhibit more general intelligence than previous AI models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks, GPT-4's performance is strikingly close to human-level performance, and often vastly surpasses prior models such as ChatGPT. Given the breadth and depth of GPT-4's capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system. In our exploration of GPT-4, we put special emphasis on discovering its limitations, and we discuss the challenges ahead for advancing towards deeper and more comprehensive versions of AGI, including the possible need for pursuing a new paradigm that moves beyond next-word prediction. We conclude with reflections on societal influences of the recent technological leap and future research directions.},
  date        = {2023-03-22},
  eprint      = {2303.12712v5},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/2303.12712v5:PDF},
  keywords    = {cs.CL, cs.AI},
}

@Article{Lohmann_2003,
  author    = {Heidemarie Lohmann and Michael Tomasello},
  title     = {The Role of Language in the Development of False Belief Understanding: A Training Study},
  journal   = {Child Development},
  year      = {2003},
  volume    = {74},
  number    = {4},
  pages     = {1130--1144},
  month     = {jul},
  doi       = {10.1111/1467-8624.00597},
  publisher = {Wiley},
}

@Article{Pyers_2009,
  author    = {Jennie E. Pyers and Ann Senghas},
  title     = {Language Promotes False-Belief Understanding},
  journal   = {Psychological Science},
  year      = {2009},
  volume    = {20},
  number    = {7},
  pages     = {805--812},
  month     = {jul},
  doi       = {10.1111/j.1467-9280.2009.02377.x},
  publisher = {{SAGE} Publications},
}

@Article{Siegelmann_1995,
  author    = {Hava T. Siegelmann},
  title     = {Computation Beyond the Turing Limit},
  journal   = {Science},
  year      = {1995},
  volume    = {268},
  number    = {5210},
  pages     = {545--548},
  month     = {apr},
  doi       = {10.1126/science.268.5210.545},
  publisher = {American Association for the Advancement of Science ({AAAS})},
}

@Article{Hauser_2002,
  author    = {Marc D. Hauser and Noam Chomsky and W. Tecumseh Fitch},
  title     = {The Faculty of Language: What Is It, Who Has It, and How Did It Evolve?},
  journal   = {Science},
  year      = {2002},
  volume    = {298},
  number    = {5598},
  pages     = {1569--1579},
  month     = {nov},
  doi       = {10.1126/science.298.5598.1569},
  publisher = {American Association for the Advancement of Science ({AAAS})},
}

@Comment{jabref-meta: databaseType:bibtex;}
