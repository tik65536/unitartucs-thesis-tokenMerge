Run Para : Namespace(epoch=1000, batch=1000, maxlen=600, HPCTrain=0, trainSize=15000, optstep=1, dynamicOpt=0, RMS=0, codewordNorm=0, preprocesstext=1.0, embeddingDim=256, seqlen=25, slide=25, GRU=0, hiddenLayer=3, hiddenSize=3, bidirection=1, withHiddenState=1, numconv1d=0, groupRelu=1, convpredict=0, predictkernelsize=2, interventionP=1.0, mergeRate=3, maxmerge=3, minmerge=2, remark='Curl_RandMerge_R33_dim256_4Class_', inhibit=[], inhibiteps=0.0, numClass=3, permuteidx=None, onlyMerge=[], skipPOS=[], consecutive=0)
Traing PD shape : (15000, 2)
count    15000.000000
mean         0.500000
std          0.500017
min          0.000000
25%          0.000000
50%          0.500000
75%          1.000000
max          1.000000
Name: label, dtype: float64
Test PD shape : (3000, 2)
count    3000.000000
mean        0.500000
std         0.500083
min         0.000000
25%         0.000000
50%         0.500000
75%         1.000000
max         1.000000
Name: label, dtype: float64
Vocab len: 183398
Embedding Space 2 Conv1D block size:2
torch.Size([3, 6])
weight_ih_l0 torch.Size([12, 256])
weight_hh_l0 torch.Size([12, 3])
weight_ih_l0_reverse torch.Size([12, 256])
weight_hh_l0_reverse torch.Size([12, 3])
weight_ih_l1 torch.Size([12, 6])
weight_hh_l1 torch.Size([12, 3])
weight_ih_l1_reverse torch.Size([12, 6])
weight_hh_l1_reverse torch.Size([12, 3])
weight_ih_l2 torch.Size([12, 6])
weight_hh_l2 torch.Size([12, 3])
weight_ih_l2_reverse torch.Size([12, 6])
weight_hh_l2_reverse torch.Size([12, 3])
[25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25]
Epoch: 0 Batch TrainDoc# 1000, Switch:1, Preprocess:1, AvgLoss:1.3931, AvgAccy:0.522, AvgAccy2:0.522, DiffPOS:0.000
Epoch:  0 Training Finished, AvgTrainingLoss:1.393123, AvgAccy:0.522, DiffPOS:0.000, Time:62.3546, Time2:25.6599
Epoch:  0 Training Finished, Merge:[('s0e_s0e_s0e', 6000), ('s0e_s0e', 3000), ('NOUN_NOUN', 2351), ('NOUN_NOUN_NOUN', 1628), ('NOUN_VERB', 1546), ('ADJ_NOUN', 1469), ('VERB_NOUN', 1372), ('NOUN_VERB_NOUN', 1201), ('NOUN_NOUN_VERB', 1078), ('ADJ_NOUN_NOUN', 1071)]
